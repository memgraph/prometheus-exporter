name: Build Images
concurrency:
  group: ${{ github.head_ref || github.sha }}
  cancel-in-progress: true


on:
  push:
  workflow_dispatch:
    inputs:
      push_to_s3:
        type: boolean
        default: true
        description: "Push image to S3 bucket"
      test:
        type: boolean
        default: false
        description: "Push to prometheus-exporter-test directory"

jobs:
  build_images:
    strategy:
      matrix:
        arch: ["amd64", "arm64"]

    runs-on: ${{ (matrix.arch == 'arm64') && fromJSON('["self-hosted", "ARM64"]') || fromJSON('["self-hosted", "X64"]') }}
    steps:
      - name: Checkout repository 
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Docker Buildx
        id: buildx
        uses: docker/setup-buildx-action@v3

      - name: Setup AWS credentials
        if: ${{ inputs.push_to_s3 }}
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.s3_region }}

      - name: Extract Tag From pyproject.toml
        run: |
          tag="$(grep -Po '^version\s*=\s*"\K[0-9]+\.[0-9]+\.[0-9]+' pyproject.toml)"
          repo_tag="memgraph/prometheus-exporter:${tag}"
          echo "TAG=$tag" >> $GITHUB_ENV
          echo "REPO_TAG=$repo_tag" >> $GITHUB_ENV

      - name: Set Name and Output Directory
        run: |
          name="mg-prometheus-exporter-${tag}${{ (matrix.arch == 'arm64') && '-arm64' || '' }}-docker.tar.gz"
          echo "FILE_NAME=$name" >> $GITHUB_ENV
        
          outdir="prometheus-exporter${{ inputs.test == true && '-test' || '' }}/v${{ env.TAG }}"
          echo "OUT_DIR=$outdir" >> $GITHUB_ENV

          echo "Output: $outdir/$name"

      - name: Build Image
        run: |
          docker build --tag "${{ env.REPO_TAG }}" --load .
      
      - name: Save Image
        run: |
          mkdir -p output
          docker save "${{ env.REPO_TAG }}" | gzip > "output/$FILE_NAME"
      
      - name: Push Image to S3
        if: ${{ inputs.push_to_s3 }}
        env:
          AWS_S3_BUCKET: "deps.memgraph.io"
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: "eu-west-1"
          SOURCE_DIR: "output"
          DEST_DIR: "${{ env.OUT_DIR }}/"
        run: |
          max_attempts=3
          attempt_num=1
          until [ $attempt_num -gt $max_attempts ]
          do
            echo "Attempt $attempt_num..."
            # Replace the next line with your actual s3 sync command or action logic
            aws s3 sync $SOURCE_DIR s3://$AWS_S3_BUCKET/$DEST_DIR && break || {
              echo "Attempt $attempt_num failed. Retrying in 5 seconds..."
              sleep 5
              attempt_num=$((attempt_num+1))
            }
          done
      
      - name: Cleanup
        if: always()
        run: |
          docker rmi "${{ env.REPO_TAG }}" || true